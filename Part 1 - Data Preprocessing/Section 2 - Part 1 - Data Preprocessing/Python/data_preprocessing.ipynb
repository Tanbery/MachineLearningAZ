{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"data_preprocessing_template.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOD2/gZgY69JdiiGJVNfu7s"},"kernelspec":{"name":"python3","display_name":"Python 3.9.6 64-bit"},"language_info":{"name":"python","version":"3.9.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"interpreter":{"hash":"864cefb13d729383c3394a7484fb8b347152a456078d40ac4c14856748a83f41"}},"cells":[{"cell_type":"markdown","source":["# Data Preprocessing Template"],"metadata":{"id":"WOw8yMd1VlnD","colab_type":"text"}},{"cell_type":"markdown","source":["## Importing the libraries"],"metadata":{"id":"NvUGC8QQV6bV","colab_type":"text"}},{"cell_type":"code","execution_count":3,"source":["import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import pandas as pd"],"outputs":[],"metadata":{"id":"wfFEXZC0WS-V","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Importing the dataset"],"metadata":{"id":"fhYaZ-ENV_c5","colab_type":"text"}},{"cell_type":"code","execution_count":4,"source":["dataset = pd.read_csv('Data.csv')\r\n","X = dataset.iloc[:, :-1].values\r\n","y = dataset.iloc[:, -1].values\r\n","# X"],"outputs":[],"metadata":{"id":"aqHTg9bxWT_u","colab_type":"code","colab":{}}},{"cell_type":"markdown","source":["## Splitting the dataset into the Training set and Test set"],"metadata":{"id":"3abSxRqvWEIB","colab_type":"text"}},{"cell_type":"code","execution_count":5,"source":["# from sklearn.model_selection import train_test_split\r\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Taking care of missing data"],"metadata":{}},{"cell_type":"code","execution_count":6,"source":["from sklearn.impute import SimpleImputer\r\n","imputer= SimpleImputer(missing_values=np.nan, strategy='mean')\r\n","imputer.fit(X[:,1:3])\r\n","X[:,1:3] = imputer.transform(X[:,1:3])\r\n","# X"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Encoding categorical data (France, Germany, Spain)"],"metadata":{}},{"cell_type":"code","execution_count":7,"source":["from sklearn.compose import ColumnTransformer\r\n","from sklearn.preprocessing import OneHotEncoder\r\n","\r\n","#create vertors instead of LabelEncoder for X[0] France=1,0,0 Germany=0,1,0 Spain=0,0,1 \r\n","ct  = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder=\"passthrough\")\r\n","X = np.array( ct.fit_transform(X))\r\n","# X"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Encoding categorical data (Purchased(yes,no) ==> 0,1)"],"metadata":{}},{"cell_type":"code","execution_count":8,"source":["from sklearn.preprocessing import LabelEncoder\r\n","le = LabelEncoder()\r\n","y = le.fit_transform(y) \r\n","# y"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Splitting the dataset into Training/Test set"],"metadata":{}},{"cell_type":"code","execution_count":9,"source":["from sklearn.model_selection import train_test_split\r\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"],"outputs":[],"metadata":{}},{"cell_type":"markdown","source":["## Feature Scaling"],"metadata":{}},{"cell_type":"code","execution_count":13,"source":["from sklearn.preprocessing import StandardScaler\r\n","\r\n","sc=StandardScaler()\r\n","# print(X_train)\r\n","X_train[:,3:] = sc.fit_transform(X_train[:,3:])\r\n","X_test[:,3:] = sc.fit_transform(X_test[:,3:])\r\n","# X_train\r\n","X_test"],"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.0, 1.0, 0.0, -1.0, -1.0],\n","       [1.0, 0.0, 0.0, 1.0, 1.0]], dtype=object)"]},"metadata":{},"execution_count":13}],"metadata":{}}]}